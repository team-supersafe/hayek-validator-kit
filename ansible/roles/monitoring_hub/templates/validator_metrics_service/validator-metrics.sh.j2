#!/bin/bash

###############################################################################
# Early safety: wait a bit and configure shell
###############################################################################
sleep 5                             # Give the environment a moment to settle
trap '' PIPE                        # Ignore SIGPIPE to avoid "Broken pipe"
set -euo pipefail                   # Abort on unhandled error / undefined var

###############################################################################
# Verify required binaries are present
###############################################################################
for bin in curl jq bc awk grep date timeout sed tr wc; do
  command -v "$bin" >/dev/null || { echo "‚ùå Required binary '$bin' not found"; exit 1; }
done

###############################################################################
# UNIFIED CONFIGURATION (Using Environment Variables)
###############################################################################

# ===== LOAD ENVIRONMENT VARIABLES =====
# Try to source environment file if it exists
ENV_FILE="/usr/local/etc/validator-metrics.env"
if [[ -f "$ENV_FILE" ]]; then
  echo "üîß Loading environment variables from $ENV_FILE"
  source "$ENV_FILE"
else
  echo "‚ö†Ô∏è Environment file not found at $ENV_FILE, using fallback values"
fi

# ===== VALIDATOR CONFIGURATION BY NETWORK =====
# MAINNET - Use environment variables (NO FALLBACKS)
MAINNET_VOTE_ACCOUNT="${MAINNET_VOTE_ACCOUNT:-}"
MAINNET_IDENTITY="${MAINNET_IDENTITY:-}"
MAINNET_RPC_API="${SOLANA_MAINNET_RPC:-}"
MAINNET_HOST="${MAINNET_NAME_SUFFIX:-}"
MAINNET_STAKEWIZ_ENABLED={{ solana.network.mainnet.stakewiz | lower }}
MAINNET_GOSSIP_ENABLED={{ solana.network.mainnet.enabled | lower }}
MAINNET_JITO_MEV_ENABLED={{ solana.network.mainnet.jito_mev | lower }}

# TESTNET - Use environment variables (NO FALLBACKS)
TESTNET_VOTE_ACCOUNT="${TESTNET_VOTE_ACCOUNT:-}"
TESTNET_IDENTITY="${TESTNET_IDENTITY:-}"
TESTNET_RPC_API="${SOLANA_TESTNET_RPC:-}"
TESTNET_HOST="${TESTNET_NAME_SUFFIX:-}"
TESTNET_STAKEWIZ_ENABLED={{ solana.network.testnet.stakewiz | lower }}
TESTNET_GOSSIP_ENABLED={{ solana.network.testnet.enabled | lower }}
TESTNET_JITO_MEV_ENABLED={{ solana.network.testnet.jito_mev | lower }}

# DEBUG - Use environment variables (NO FALLBACKS)
DEBUG_VOTE_ACCOUNT="${DEBUG_VOTE_ACCOUNT:-}"
DEBUG_IDENTITY="${DEBUG_IDENTITY:-}"
DEBUG_RPC_API="${SOLANA_MAINNET_RPC:-}"
DEBUG_HOST="${DEBUG_HOST:-}"
DEBUG_STAKEWIZ_ENABLED={{ solana.network.debug.stakewiz | lower }}
DEBUG_GOSSIP_ENABLED={{ solana.network.debug.enabled | lower }}
DEBUG_JITO_MEV_ENABLED={{ solana.network.debug.jito_mev | lower }}

# DEVNET - Use environment variables (NO FALLBACKS)
DEVNET_VOTE_ACCOUNT="${DEVNET_VOTE_ACCOUNT:-}"
DEVNET_IDENTITY="${DEVNET_IDENTITY:-}"
DEVNET_RPC_API="${SOLANA_MAINNET_RPC:-}"
DEVNET_HOST="${DEVNET_HOST:-}"
DEVNET_STAKEWIZ_ENABLED={{ solana.network.devnet.stakewiz | lower }}
DEVNET_GOSSIP_ENABLED={{ solana.network.devnet.enabled | lower }}
DEVNET_JITO_MEV_ENABLED={{ solana.network.devnet.jito_mev | lower }}

# LOCALNET - Use environment variables (NO FALLBACKS)
LOCALNET_VOTE_ACCOUNT="${LOCALNET_VOTE_ACCOUNT:-}"
LOCALNET_IDENTITY="${LOCALNET_IDENTITY:-}"
LOCALNET_RPC_API="${SOLANA_MAINNET_RPC:-}"
LOCALNET_HOST="${LOCALNET_HOST:-}"
LOCALNET_STAKEWIZ_ENABLED={{ solana.network.localnet.stakewiz | lower }}
LOCALNET_GOSSIP_ENABLED={{ solana.network.localnet.enabled | lower }}
LOCALNET_JITO_MEV_ENABLED={{ solana.network.localnet.jito_mev | lower }}


# ===== INFLUXDB V2 CONFIGURATION =====
INFLUX_URL="${INFLUX_URL:-}"
INFLUX_ORG="${INFLUX_ORG:-}"
INFLUX_BUCKET="${INFLUX_BUCKET:-}"
INFLUX_TOKEN="${INFLUX_TOKEN:-}"

# ===== VALIDATE CRITICAL ENVIRONMENT VARIABLES =====
MISSING_VARS=()

# Check InfluxDB v2 credentials
[[ -z "$INFLUX_URL" ]] && MISSING_VARS+=("INFLUX_URL")
[[ -z "$INFLUX_ORG" ]] && MISSING_VARS+=("INFLUX_ORG")
[[ -z "$INFLUX_BUCKET" ]] && MISSING_VARS+=("INFLUX_BUCKET")
[[ -z "$INFLUX_TOKEN" ]] && MISSING_VARS+=("INFLUX_TOKEN")

# Check validator keys
[[ -z "$MAINNET_VOTE_ACCOUNT" ]] && MISSING_VARS+=("MAINNET_VOTE_ACCOUNT")
[[ -z "$MAINNET_IDENTITY" ]] && MISSING_VARS+=("MAINNET_IDENTITY")
[[ -z "$TESTNET_VOTE_ACCOUNT" ]] && MISSING_VARS+=("TESTNET_VOTE_ACCOUNT")
[[ -z "$TESTNET_IDENTITY" ]] && MISSING_VARS+=("TESTNET_IDENTITY")
[[ -z "$DEBUG_VOTE_ACCOUNT" ]] && MISSING_VARS+=("DEBUG_VOTE_ACCOUNT")
[[ -z "$DEBUG_IDENTITY" ]] && MISSING_VARS+=("DEBUG_IDENTITY")
[[ -z "$DEVNET_VOTE_ACCOUNT" ]] && MISSING_VARS+=("DEVNET_VOTE_ACCOUNT")
[[ -z "$DEVNET_IDENTITY" ]] && MISSING_VARS+=("DEVNET_IDENTITY")
[[ -z "$LOCALNET_VOTE_ACCOUNT" ]] && MISSING_VARS+=("LOCALNET_VOTE_ACCOUNT")
[[ -z "$LOCALNET_IDENTITY" ]] && MISSING_VARS+=("LOCALNET_IDENTITY")

# Check RPC endpoints
[[ -z "$SOLANA_MAINNET_RPC" ]] && MISSING_VARS+=("SOLANA_MAINNET_RPC")
[[ -z "$SOLANA_TESTNET_RPC" ]] && MISSING_VARS+=("SOLANA_TESTNET_RPC")
[[ -z "$SOLANA_DEVNET_RPC" ]] && MISSING_VARS+=("SOLANA_DEVNET_RPC")
[[ -z "$SOLANA_LOCALNET_RPC" ]] && MISSING_VARS+=("SOLANA_LOCALNET_RPC")

# Check host names
[[ -z "$MAINNET_NAME_SUFFIX" ]] && MISSING_VARS+=("MAINNET_NAME_SUFFIX")
[[ -z "$TESTNET_NAME_SUFFIX" ]] && MISSING_VARS+=("TESTNET_NAME_SUFFIX")
[[ -z "$DEBUG_NAME_SUFFIX" ]] && MISSING_VARS+=("DEBUG_NAME_SUFFIX")
[[ -z "$DEVNET_NAME_SUFFIX" ]] && MISSING_VARS+=("DEVNET_NAME_SUFFIX")
[[ -z "$LOCALNET_NAME_SUFFIX" ]] && MISSING_VARS+=("LOCALNET_NAME_SUFFIX")

# Check Solana binary path
[[ -z "$SOLANA_BIN" ]] && MISSING_VARS+=("SOLANA_BIN")

{% raw %}
# Exit if any critical variables are missing
if [[ ${#MISSING_VARS[@]} -gt 0 ]]; then
{% endraw %}
  echo "‚ùå ERROR: Missing required environment variables:"
  for var in "${MISSING_VARS[@]}"; do
    echo "  - $var"
  done
  echo ""
  echo "Please ensure these variables are defined in $ENV_FILE"
  echo "The script cannot run safely without these credentials."
  exit 1
fi

echo "‚úÖ All critical environment variables are set"

# ===== PROCESSING TOGGLES =====
PROCESS_MAINNET={{ solana.network.mainnet.enabled | lower }}
PROCESS_TESTNET={{ solana.network.testnet.enabled | lower }}
PROCESS_DEBUG={{ solana.network.debug.enabled | lower }}
PROCESS_DEVNET={{ solana.network.devnet.enabled | lower }}
PROCESS_LOCALNET={{ solana.network.localnet.enabled | lower }}

# ===== ABSOLUTE PATH TO SOLANA BIN =====
SOLANA_BIN="${SOLANA_BIN:-}"

###############################################################################
# Locate Solana binary if the default path does not exist
###############################################################################
if [ ! -x "$SOLANA_BIN" ]; then
  echo "‚ö†Ô∏è  Solana binary not found at $SOLANA_BIN ‚Äî probing PATH"
  SOLANA_BIN="$(command -v solana || true)"
  [ -x "$SOLANA_BIN" ] || { echo "‚ùå Solana CLI not found"; exit 1; }
  echo "‚úÖ Using Solana at $SOLANA_BIN"
fi

###############################################################################
# Basic connectivity checks (RPC endpoints and InfluxDB)
###############################################################################
check_endpoint () {
  local url="$1" name="$2"
  local code
  code=$(curl -s -o /dev/null -w "%{http_code}" "$url")
  echo "- $name: HTTP $code"
  [ "$code" = "200" ] || [ "$code" = "204" ] || { echo "‚ùå Cannot reach $name"; exit 1; }
}

# Robust RPC health check using JSON-RPC POST; fall back to epoch-info.
check_rpc_health () {
  local rpc_url="$1" name="$2"
  local resp health
  resp=$(curl -s --max-time 5 -X POST -H "Content-Type: application/json" -d '{"jsonrpc":"2.0","id":1,"method":"getHealth"}' "$rpc_url" || true)
  health=$(echo "$resp" | jq -r '.result // empty' 2>/dev/null || true)
  if [ -z "$health" ] || [ "$health" = "null" ]; then
    resp=$(curl -s --max-time 5 -X POST -H "Content-Type: application/json" -d '{"jsonrpc":"2.0","id":1,"method":"getEpochInfo"}' "$rpc_url" || true)
    health=$(echo "$resp" | jq -r '.result.epoch // empty' 2>/dev/null || true)
    if [ -z "$health" ] || [ "$health" = "null" ]; then
      echo "‚ùå RPC health check failed for $name"; exit 1; fi
  fi
  echo "- $name RPC health OK"
}

echo "üîç Checking connectivity..."
$PROCESS_MAINNET   && check_rpc_health "$MAINNET_RPC_API" "Mainnet"
$PROCESS_TESTNET   && check_rpc_health "$TESTNET_RPC_API" "Testnet"
$PROCESS_DEBUG     && check_rpc_health "$DEBUG_RPC_API" "Debug"
$PROCESS_DEVNET    && check_rpc_health "$DEVNET_RPC_API" "Devnet"
$PROCESS_LOCALNET  && check_rpc_health "$LOCALNET_RPC_API" "Localnet"
check_endpoint "$INFLUX_URL/ping" "InfluxDB"
echo

###############################################################################
# VALIDATOR METRICS FUNCTIONS (from send_validator_metrics_jito.sh)
###############################################################################

# ===== FUNCTION TO CALCULATE SLOT DURATION DYNAMICALLY =====
get_slot_duration_ms() {
  local RPC_URL="$1"
  local CLUSTER="$2"

  local CMD=""
  case "$CLUSTER" in
    mainnet) CMD="$SOLANA_BIN -u m epoch-info" ;;
    testnet) CMD="$SOLANA_BIN -u t epoch-info" ;;
    devnet) CMD="$SOLANA_BIN -u d epoch-info" ;;
    localnet) CMD="$SOLANA_BIN -u l epoch-info" ;;
    debug) CMD="$SOLANA_BIN -u m epoch-info" ;;
    *) CMD="$SOLANA_BIN epoch-info" ;;
  esac

  local EPOCH_CLI_INFO=$($CMD 2>/dev/null)
  if [[ -z "$EPOCH_CLI_INFO" ]]; then
    echo "420"
    return
  fi

  local EPOCH_TOTAL_TIME=$(echo "$EPOCH_CLI_INFO" | grep "Epoch Completed Time:" | sed 's/.*\/\(.*\) (.*/\1/')
  if [[ -z "$EPOCH_TOTAL_TIME" ]]; then
    echo "420"
    return
  fi

  local DAYS=$(echo "$EPOCH_TOTAL_TIME" | grep -o "[0-9]\+day" | sed 's/day//')
  local HOURS=$(echo "$EPOCH_TOTAL_TIME" | grep -o "[0-9]\+h" | sed 's/h//')
  local MINUTES=$(echo "$EPOCH_TOTAL_TIME" | grep -o "[0-9]\+m" | sed 's/m//')
  local SECONDS=$(echo "$EPOCH_TOTAL_TIME" | grep -o "[0-9]\+s" | sed 's/s//')

  DAYS=${DAYS:-0}
  HOURS=${HOURS:-0}
  MINUTES=${MINUTES:-0}
  SECONDS=${SECONDS:-0}

  local TOTAL_SECONDS=$((DAYS*86400 + HOURS*3600 + MINUTES*60 + SECONDS))
  local SLOTS_PER_EPOCH=432000
  local SLOT_DURATION_MS=$(awk -v secs="$TOTAL_SECONDS" -v slots="$SLOTS_PER_EPOCH" 'BEGIN { printf "%.0f", (secs / slots) * 1000 }')

  if [[ -z "$SLOT_DURATION_MS" || "$SLOT_DURATION_MS" -lt 100 || "$SLOT_DURATION_MS" -gt 1000 ]]; then
    echo "420"
  else
    echo "$SLOT_DURATION_MS"
  fi
}

# ===== FUNCTION TO GET RPC VERSION =====
get_rpc_version() {
  local IDENTITY_KEY="$1"
  local RPC_URL="$2"
  curl -s --max-time 10 "$RPC_URL" -X POST -H "Content-Type: application/json" -d '{
    "jsonrpc": "2.0",
    "id": 1,
    "method": "getAccountInfo",
    "params": ["'"$IDENTITY_KEY"'", {"encoding": "base58"}]
  }' | jq -r '.result.context.apiVersion'
}

# ===== FUNCTION TO GET GOSSIP VERSION FROM SOLANA CLI =====
get_gossip_version() {
  local IDENTITY_KEY="$1"
  local CLUSTER="$2"
  local CMD=""
  local GOSSIP_VERSION=""

  case "$CLUSTER" in
    mainnet) CMD="$SOLANA_BIN -u m -v gossip" ;;
    testnet) CMD="timeout 15 $SOLANA_BIN -u t -v gossip" ;;
    devnet) CMD="$SOLANA_BIN -u d -v gossip" ;;
    localnet) CMD="$SOLANA_BIN -u l -v gossip" ;;
    debug) CMD="$SOLANA_BIN -u m -v gossip" ;;
    *) return ;;
  esac

  GOSSIP_LINE=$($CMD 2>/dev/null | grep "$IDENTITY_KEY")
  if [[ -n "$GOSSIP_LINE" ]]; then
    GOSSIP_VERSION=$(echo "$GOSSIP_LINE" | awk -F'|' '{gsub(/^[ \t]+|[ \t]+$/, "", $7); print $7}')
  fi

  echo "$GOSSIP_VERSION"
}

# ===== FUNCTION TO GET TVC RANK =====
get_tvc_rank() {
  local TVC_RANK_DATA=$(curl -s --max-time 5 "http://localhost:8000/tvc-rank")

  if echo "$TVC_RANK_DATA" | jq -e '.output' >/dev/null 2>&1; then
    local RANK=$(echo "$TVC_RANK_DATA" | jq -r '.output' | grep -o '[0-9]\+')
    echo "$RANK"
  else
    echo ""
  fi
}

# ===== FUNCTION TO GET AND SEND JITO MEV STATS PER EPOCH (NEW EPOCHS ONLY) =====
send_jito_mev_epochs_new_only() {
  local VOTE_ACCOUNT="$1"
  local IDENTITY_KEY="$2"
  local HOST="$3"
  local JITO_API_URL="https://kobe.mainnet.jito.network/api/v1/validators/${VOTE_ACCOUNT}"

  # Get the latest epoch from InfluxDB
  # epoch will be stored as a numeric field to allow aggregation
  local LATEST_EPOCH_FLUX="from(bucket: \"${INFLUX_BUCKET}\") |> range(start: -30d) |> filter(fn: (r) => r._measurement == \"jito_mev_epochs\" and r.host == \"${HOST}\" and r.pubkey == \"${IDENTITY_KEY}\") |> filter(fn: (r) => r._field == \"epoch\") |> max()"
  local LATEST_EPOCH_DATA=$(curl -s -XPOST "${INFLUX_URL}/api/v2/query?org=${INFLUX_ORG}" \
    -H "Authorization: Token ${INFLUX_TOKEN}" \
    -H "Content-Type: application/vnd.flux" \
    --data-raw "$LATEST_EPOCH_FLUX")
  local LATEST_EPOCH=$(echo "$LATEST_EPOCH_DATA" | jq -r '.results[0].series[0].values[0][1] // 0' 2>/dev/null || echo 0)

  # Get Jito MEV data with 10 second timeout
  local JITO_MEV_DATA=$(curl -s --max-time 10 "$JITO_API_URL")

  # Check if we got valid JSON array response
  if echo "$JITO_MEV_DATA" | jq -e 'type == "array"' >/dev/null 2>&1; then
    echo "üîç Processing new Jito MEV epochs for $HOST (latest in DB: $LATEST_EPOCH)"

    # Process each epoch individually, only if it's newer than the latest in DB
    echo "$JITO_MEV_DATA" | jq -c '.[]' | while read -r EPOCH_DATA; do
      local EPOCH=$(echo "$EPOCH_DATA" | jq -r '.epoch')

      # Only process epochs newer than the latest in database
      if [[ "$EPOCH" -gt "$LATEST_EPOCH" ]]; then
        local MEV_REWARDS_LAMPORTS=$(echo "$EPOCH_DATA" | jq -r '.mev_rewards')
        local MEV_COMMISSION_BPS=$(echo "$EPOCH_DATA" | jq -r '.mev_commission_bps')

        {% raw %}
        # Calculate operator rewards in lamports for this epoch
        local OPERATOR_REWARDS_LAMPORTS=$(awk -v rewards="$MEV_REWARDS_LAMPORTS" -v commission="$MEV_COMMISSION_BPS" 'BEGIN { printf "%.0f", (rewards * commission) / 10000 }')

        # Convert lamports to SOL (1 SOL = 1,000,000,000 lamports)
        local MEV_REWARDS_SOL=$(awk -v lamports="$MEV_REWARDS_LAMPORTS" 'BEGIN { printf "%.9f", lamports / 1000000000 }')
        local OPERATOR_REWARDS_SOL=$(awk -v lamports="$OPERATOR_REWARDS_LAMPORTS" 'BEGIN { printf "%.9f", lamports / 1000000000 }')
        {% endraw %}

        # Create InfluxDB line protocol with both lamports and SOL
        local TIMESTAMP=$(date +%s%N)
        local TAGS="host=${HOST},pubkey=${IDENTITY_KEY}"
        local FIELDS="epoch=${EPOCH},jito_mev_rewards_lamports=${MEV_REWARDS_LAMPORTS},jito_mev_rewards_sol=${MEV_REWARDS_SOL},jito_mev_commission_bps=${MEV_COMMISSION_BPS},jito_operator_rewards_lamports=${OPERATOR_REWARDS_LAMPORTS},jito_operator_rewards_sol=${OPERATOR_REWARDS_SOL}"

        local LINE="jito_mev_epochs,${TAGS} ${FIELDS} ${TIMESTAMP}"

        # Send to InfluxDB v2
        curl -s -XPOST "${INFLUX_URL}/api/v2/write?org=${INFLUX_ORG}&bucket=${INFLUX_BUCKET}&precision=ns" \
          -H "Authorization: Token ${INFLUX_TOKEN}" \
          --data-raw "$LINE"

        echo "‚úÖ New Epoch $EPOCH - MEV: ${MEV_REWARDS_SOL} SOL (${MEV_REWARDS_LAMPORTS} lamports), Operator: ${OPERATOR_REWARDS_SOL} SOL (${OPERATOR_REWARDS_LAMPORTS} lamports)"
      else
        echo "‚è≠Ô∏è Epoch $EPOCH already exists in database (<= $LATEST_EPOCH), skipping..."
      fi
    done

  else
    echo "‚ùå Error: Could not get Jito MEV data for $HOST"
  fi
}

# ===== FUNCTION TO GET NEXT EPOCH LEADER SLOT COUNT =====
get_next_epoch_leader_slot_count() {
  local IDENTITY_KEY="$1"
  local CLUSTER="$2"
  local CURRENT_EPOCH
  local NEXT_EPOCH
  local SLOTS_RAW
  local CMD=""

  case "$CLUSTER" in
    mainnet) CMD="$SOLANA_BIN -u m" ;;
    testnet) CMD="$SOLANA_BIN -u t" ;;
    devnet) CMD="$SOLANA_BIN -u d" ;;
    localnet) CMD="$SOLANA_BIN -u l" ;;
    debug) CMD="$SOLANA_BIN -u m" ;;
    *) echo "0"; return ;;
  esac

  CURRENT_EPOCH=$($CMD epoch 2>/dev/null | awk '{print $1}')
  if [[ -z "$CURRENT_EPOCH" || ! "$CURRENT_EPOCH" =~ ^[0-9]+$ ]]; then
    echo ""
    return
  fi

  NEXT_EPOCH=$((CURRENT_EPOCH + 1))
  SLOTS_RAW=$($CMD leader-schedule --epoch "$NEXT_EPOCH" 2>/dev/null | grep "$IDENTITY_KEY")

  if [[ -n "$SLOTS_RAW" ]]; then
    echo "$SLOTS_RAW" | awk -F':' '{gsub(/[ \[\]]/, "", $2); print $2}' | tr ',' '\n' | wc -l
  else
    echo "0"
  fi
}

# ===== FUNCTION TO SEND VALIDATOR METRICS TO INFLUXDB =====
send_validator_metrics() {
  local VOTE_ACCOUNT="$1"
  local IDENTITY_KEY="$2"
  local RPC_URL="$3"
  local HOST="$4"
  local STAKEWIZ_ENABLED="$5"
  local GOSSIP_ENABLED="$6"
  local JITO_MEV_ENABLED="$7"

  echo "üìä Collecting validator metrics for $HOST..."

  ACTIVATING_STAKE=""
  RANK=""
  WIZ_SCORE=""
  IS_JITO=""
  GOSSIP_VERSION=""
  TVC_RANK=""

  if [[ "$STAKEWIZ_ENABLED" == true ]]; then
    STAKEWIZ_EPOCH_DATA=$(curl -s --max-time 5 "https://api.stakewiz.com/validator_epoch_stakes/${VOTE_ACCOUNT}")
    if echo "$STAKEWIZ_EPOCH_DATA" | jq -e 'type == "array"' >/dev/null 2>&1; then
      ACTIVATING_STAKE=$(echo "$STAKEWIZ_EPOCH_DATA" | jq -r '.[0].activating_stake // empty')
    fi

    STAKEWIZ_VAL_DATA=$(curl -s --max-time 5 "https://api.stakewiz.com/validator/${VOTE_ACCOUNT}")
    if echo "$STAKEWIZ_VAL_DATA" | jq -e 'type == "object"' >/dev/null 2>&1; then
      RANK=$(echo "$STAKEWIZ_VAL_DATA" | jq -r '.rank // empty')
      WIZ_SCORE=$(echo "$STAKEWIZ_VAL_DATA" | jq -r '.wiz_score // empty')
      IS_JITO=$(echo "$STAKEWIZ_VAL_DATA" | jq -r '.is_jito // empty')
    fi
  fi

  # Determine the cluster based on the host
  CLUSTER=""
  [[ "$HOST" == "$MAINNET_HOST" ]] && CLUSTER="mainnet"
  [[ "$HOST" == "$TESTNET_HOST" ]] && CLUSTER="testnet"
  [[ "$HOST" == "$DEBUG_HOST" ]] && CLUSTER="debug"
  [[ "$HOST" == "$DEVNET_HOST" ]] && CLUSTER="devnet"
  [[ "$HOST" == "$LOCALNET_HOST" ]] && CLUSTER="localnet"

  # Get TVC Rank for MAINNET only
  if [[ "$HOST" == "$MAINNET_HOST" ]]; then
    TVC_RANK=$(get_tvc_rank)
  fi

  # Get and send Jito MEV metrics per epoch (mainnet only)
  if [[ "$JITO_MEV_ENABLED" == true && "$HOST" == "$MAINNET_HOST" ]]; then
    send_jito_mev_epochs_new_only "$VOTE_ACCOUNT" "$IDENTITY_KEY" "$HOST"
  fi

  RPC_VERSION=$(get_rpc_version "$IDENTITY_KEY" "$RPC_URL")

  if [[ "$GOSSIP_ENABLED" == true ]]; then
    GOSSIP_VERSION=$(get_gossip_version "$IDENTITY_KEY" "$CLUSTER")
  fi

  # Get the slot duration for this specific cluster
  SLOT_DURATION_MS=$(get_slot_duration_ms "$RPC_URL" "$CLUSTER")

  EPOCH_INFO=$(curl -s --max-time 10 "$RPC_URL" -X POST -H "Content-Type: application/json" -d '{"jsonrpc": "2.0", "id": 1, "method": "getEpochInfo"}')
  LEADER_SCHEDULE=$(curl -s --max-time 10 "$RPC_URL" -X POST -H "Content-Type: application/json" -d '{"jsonrpc": "2.0", "id": 1, "method": "getLeaderSchedule", "params": [null, {"identity": "'"$IDENTITY_KEY"'"}]}')
  CURRENT_SLOT=$(curl -s --max-time 10 "$RPC_URL" -X POST -H "Content-Type: application/json" -d '{"jsonrpc": "2.0", "id": 1, "method": "getSlot"}' | jq -r '.result')
  SLOT_INDEX=$(echo "$EPOCH_INFO" | jq -r '.result.slotIndex')

  # Calculate the time until the end of the epoch
  SLOTS_PER_EPOCH=$(echo "$EPOCH_INFO" | jq -r '.result.slotsInEpoch')
  SLOTS_REMAINING_IN_EPOCH=$((SLOTS_PER_EPOCH - SLOT_INDEX))
  TIME_TO_EPOCH_END_S=$(awk -v slots="$SLOTS_REMAINING_IN_EPOCH" -v dur="$SLOT_DURATION_MS" 'BEGIN { printf "%.2f", (slots * dur) / 1000 }')

  # Convert to human-readable format (days, hours, minutes, seconds)
  EPOCH_END_DAYS=$(awk -v time="$TIME_TO_EPOCH_END_S" 'BEGIN { printf "%.0f", int(time / 86400) }')
  EPOCH_END_HOURS=$(awk -v time="$TIME_TO_EPOCH_END_S" -v days="$EPOCH_END_DAYS" 'BEGIN { printf "%.0f", int((time - days * 86400) / 3600) }')
  EPOCH_END_MINUTES=$(awk -v time="$TIME_TO_EPOCH_END_S" -v days="$EPOCH_END_DAYS" -v hours="$EPOCH_END_HOURS" 'BEGIN { printf "%.0f", int((time - days * 86400 - hours * 3600) / 60) }')
  EPOCH_END_SECONDS=$(awk -v time="$TIME_TO_EPOCH_END_S" -v days="$EPOCH_END_DAYS" -v hours="$EPOCH_END_HOURS" -v mins="$EPOCH_END_MINUTES" 'BEGIN { printf "%.0f", int(time - days * 86400 - hours * 3600 - mins * 60) }')

  # Create human-readable string
  EPOCH_END_HUMAN="${EPOCH_END_DAYS}d ${EPOCH_END_HOURS}h ${EPOCH_END_MINUTES}m ${EPOCH_END_SECONDS}s"

  # Calculate epoch completion percentage
  EPOCH_COMPLETED_PCT=$(awk -v current="$SLOT_INDEX" -v total="$SLOTS_PER_EPOCH" 'BEGIN { printf "%.2f", (current / total) * 100 }')

  LEADER_SLOTS_RAW=$(echo "$LEADER_SCHEDULE" | jq -r '.result."'"$IDENTITY_KEY"'" // empty' 2>/dev/null || echo "")
  TOTAL_LEADER_SLOTS=0
  LEADER_SLOTS="[]"
  if [[ -n "$LEADER_SLOTS_RAW" && "$LEADER_SLOTS_RAW" != "null" ]]; then
    LEADER_SLOTS=$(echo "$LEADER_SLOTS_RAW" | jq -c '.' 2>/dev/null || echo "[]")
    TOTAL_LEADER_SLOTS=$(echo "$LEADER_SLOTS" | jq 'length' 2>/dev/null || echo 0)
  fi

  if [[ -n "$ACTIVATING_STAKE" || -n "$RANK" || -n "$WIZ_SCORE" || -n "$RPC_VERSION" || -n "$GOSSIP_VERSION" || -n "$TVC_RANK" ]]; then
    TIMESTAMP=$(date +%s%N)
    TAGS="host=${HOST},pubkey=${IDENTITY_KEY}"
    FIELDS=""

    [[ -n "$ACTIVATING_STAKE" && "$ACTIVATING_STAKE" != "null" ]] && FIELDS+="activating_stake=${ACTIVATING_STAKE}"
    [[ -n "$RANK" ]] && FIELDS+="${FIELDS:+,}rank=${RANK}"
    [[ -n "$WIZ_SCORE" ]] && FIELDS+="${FIELDS:+,}wiz_score=${WIZ_SCORE}"
    [[ -n "$RPC_VERSION" && "$RPC_VERSION" != "null" ]] && FIELDS+="${FIELDS:+,}rpc_version=\"${RPC_VERSION}\""
    [[ -n "$GOSSIP_VERSION" ]] && FIELDS+="${FIELDS:+,}gossip_version=\"${GOSSIP_VERSION}\""
    [[ "$IS_JITO" == "true" ]] && FIELDS+="${FIELDS:+,}is_jito=t"
    [[ "$IS_JITO" == "false" ]] && FIELDS+="${FIELDS:+,}is_jito=f"
    [[ -n "$TVC_RANK" ]] && FIELDS+="${FIELDS:+,}tvc_rank=${TVC_RANK}"

    # Add the new slot duration and epoch end metrics
    FIELDS+="${FIELDS:+,}slot_duration_ms=${SLOT_DURATION_MS}"
    FIELDS+="${FIELDS:+,}time_to_epoch_end_s=${TIME_TO_EPOCH_END_S}"
    FIELDS+="${FIELDS:+,}time_to_epoch_end_human=\"${EPOCH_END_HUMAN}\""
    FIELDS+="${FIELDS:+,}epoch_completed_pct=${EPOCH_COMPLETED_PCT}"

    if [[ "$TOTAL_LEADER_SLOTS" -gt 0 && "$SLOT_INDEX" -ge 0 ]]; then
      NEXT_LEADER_SLOT=$(echo "$LEADER_SLOTS" | jq '[.[] | select(. > '"$SLOT_INDEX"')] | min // empty')
      LAST_LEADER_SLOT=$(echo "$LEADER_SLOTS" | jq '[.[] | select(. <= '"$SLOT_INDEX"')] | max // empty')
      LEADER_SLOTS_PASSED=$(echo "$LEADER_SLOTS" | jq '[.[] | select(. <= '"$SLOT_INDEX"')] | length')
      LEADER_SLOTS_REMAINING=$(echo "$LEADER_SLOTS" | jq '[.[] | select(. > '"$SLOT_INDEX"')] | length')
      REMAINING_RATIO=$(awk -v rem="$LEADER_SLOTS_REMAINING" -v total="$TOTAL_LEADER_SLOTS" 'BEGIN { if (total>0) printf "%.2f", (rem / total) * 100; else print 0 }')

      FIELDS+="${FIELDS:+,}leader_slot_count=${TOTAL_LEADER_SLOTS},leader_slots_passed=${LEADER_SLOTS_PASSED},leader_slots_remaining=${LEADER_SLOTS_REMAINING},leader_slots_remaining_ratio=${REMAINING_RATIO}"

      if [[ -n "$NEXT_LEADER_SLOT" ]]; then
        SLOTS_REMAINING=$((NEXT_LEADER_SLOT - SLOT_INDEX))
        TIME_TO_NEXT_LEADER_SLOT_S=$(awk -v slots="$SLOTS_REMAINING" -v dur="$SLOT_DURATION_MS" 'BEGIN { printf "%.2f", (slots * dur) / 1000 }')
        PROGRESS_TO_NEXT=$(awk -v a="$SLOT_INDEX" -v b="$NEXT_LEADER_SLOT" 'BEGIN { if (b>0) printf "%.2f", (a/b)*100; else print 0 }')
        FIELDS+="${FIELDS:+,}time_to_next_leader_slot_s=${TIME_TO_NEXT_LEADER_SLOT_S},leader_progress_percentage=${PROGRESS_TO_NEXT}"

        if [[ -n "$LAST_LEADER_SLOT" && "$NEXT_LEADER_SLOT" -ne "$LAST_LEADER_SLOT" ]]; then
          PROGRESS_SINCE_LAST=$(awk -v current="$SLOT_INDEX" -v last="$LAST_LEADER_SLOT" -v next_slot="$NEXT_LEADER_SLOT" 'BEGIN { if ((next_slot - last) > 0) printf "%.2f", ((current - last) / (next_slot - last)) * 100; else printf "0.00" }')
        else
          PROGRESS_SINCE_LAST=$(awk -v current="$SLOT_INDEX" -v next_slot="$NEXT_LEADER_SLOT" 'BEGIN { if (next_slot > 0) printf "%.2f", (current / next_slot) * 100; else printf "0.00" }')
        fi
        FIELDS+="${FIELDS:+,}leader_progress_since_last=${PROGRESS_SINCE_LAST}"

        # Add time between leader slots metric
        if [[ -n "$LAST_LEADER_SLOT" ]]; then
          SLOTS_BETWEEN=$((NEXT_LEADER_SLOT - LAST_LEADER_SLOT))
          TIME_BETWEEN_LEADER_SLOTS_S=$(awk -v slots="$SLOTS_BETWEEN" -v dur="$SLOT_DURATION_MS" 'BEGIN { printf "%.2f", (slots * dur) / 1000 }')
          FIELDS+="${FIELDS:+,}time_between_leader_slots_s=${TIME_BETWEEN_LEADER_SLOTS_S}"
        fi
      else
        FIELDS+="${FIELDS:+,}time_to_next_leader_slot_s=0,leader_progress_percentage=0.00,leader_progress_since_last=0.00"
      fi
    fi

    NEXT_EPOCH_SLOT_COUNT=$(get_next_epoch_leader_slot_count "$IDENTITY_KEY" "$CLUSTER")
    if [[ -n "$NEXT_EPOCH_SLOT_COUNT" ]]; then
      FIELDS+="${FIELDS:+,}next_epoch_leader_slot_count=${NEXT_EPOCH_SLOT_COUNT}"
    fi

    LINE="nodemonitor,${TAGS} ${FIELDS} ${TIMESTAMP}"
    curl -s -XPOST "${INFLUX_URL}/api/v2/write?org=${INFLUX_ORG}&bucket=${INFLUX_BUCKET}&precision=ns" \
      -H "Authorization: Token ${INFLUX_TOKEN}" \
      --data-raw "$LINE"
    echo "‚úÖ Validator metrics sent for $HOST"
  else
    echo "‚ùå Error: invalid validator metrics for $HOST (vote=$VOTE_ACCOUNT, id=$IDENTITY_KEY)"
  fi
}

###############################################################################
# BLOCK METRICS FUNCTIONS
###############################################################################

# ===== FUNCTION: CHECK PRODUCED BLOCKS FOR A SINGLE CLUSTER =====
check_produced_blocks () {
  local IDENTITY_KEY="$1" HOST="$2" CLUSTER="$3"
  local CMD RPC_URL

  case "$CLUSTER" in
    mainnet) CMD="$SOLANA_BIN -u m"; RPC_URL="$MAINNET_RPC_API" ;;
    testnet) CMD="$SOLANA_BIN -u t"; RPC_URL="$TESTNET_RPC_API" ;;
    devnet)  CMD="$SOLANA_BIN -u d"; RPC_URL="$DEVNET_RPC_API" ;;
    localnet) CMD="$SOLANA_BIN -u l"; RPC_URL="$LOCALNET_RPC_API" ;;
    debug)   CMD="$SOLANA_BIN -u m"; RPC_URL="$DEBUG_RPC_API" ;;
    *) echo "Unknown cluster $CLUSTER"; return 1 ;;
  esac

  echo "üîç Checking blocks for $HOST on $CLUSTER"

  local CURRENT_SLOT CURRENT_EPOCH
  CURRENT_SLOT="$($CMD slot 2>/dev/null || true)"
  CURRENT_EPOCH="$($CMD epoch 2>/dev/null | awk '{print $1}')"

  [ -n "$CURRENT_SLOT" ] || { echo "‚ö†Ô∏è  Cannot fetch current slot"; return 1; }
  [ -n "$CURRENT_EPOCH" ] || { echo "‚ö†Ô∏è  Cannot fetch current epoch"; return 1; }

  echo "‚ÑπÔ∏è  Current epoch $CURRENT_EPOCH ‚Ä¢ current slot $CURRENT_SLOT"

  # Obtain leader slots via Solana CLI for reliability
  local SLOTS_LIST SLOTS_ARRAY_LENGTH
  SLOTS_LIST=$($CMD leader-schedule | grep "$IDENTITY_KEY" | awk '{print $1}' | tr '\n' ' ')
  SLOTS_ARRAY_LENGTH=$(echo "$SLOTS_LIST" | wc -w)
  [ -n "$SLOTS_LIST" ] || { echo "‚ÑπÔ∏è  No leader slots found"; return 0; }

  # Stats counters
  local PRODUCED=0 SKIPPED=0 CACHED=0 UPDATED=0 TOTAL_REWARD=0
  local SLOTS_24H_AGO=$((CURRENT_SLOT - 216000))   # ~24h worth of slots (0.4 s/slot)

  # Iterate leader slots
  for SLOT in $SLOTS_LIST; do
    (( SLOT < SLOTS_24H_AGO )) && continue
    # Skip if data already exists and was produced
    local RESPONSE PRODUCED_IN_DB
    local BLOCK_FLUX="from(bucket: \"${INFLUX_BUCKET}\") |> range(start: -30d) |> filter(fn: (r) => r._measurement == \"blockmetrics\" and r.slot == \"$SLOT\" and r.host == \"$HOST\") |> filter(fn: (r) => r._field == \"produced\") |> sort(columns: [\"_time\"], desc: true) |> limit(n:1)"
    RESPONSE=$(curl -s -XPOST "$INFLUX_URL/api/v2/query?org=$INFLUX_ORG" \
          -H "Authorization: Token $INFLUX_TOKEN" \
          -H "Content-Type: application/vnd.flux" \
          --data-raw "$BLOCK_FLUX")
    # Parse CSV: InfluxDB CSV format has _value in column 6 (index 7 in awk) and _field in column 7 (index 8)
    # Format: ,result,table,_start,_stop,_time,_value,_field,_measurement,epoch,host,pubkey,slot
    PRODUCED_IN_DB=$(echo "$RESPONSE" | grep -v '^#' | awk -F',' 'NR>1 && $8=="produced" {print $7; exit}' 2>/dev/null | tr -d '[:space:]')
    if [ -n "$PRODUCED_IN_DB" ] && [ "$PRODUCED_IN_DB" = "1" ]; then
      ((CACHED++))
      continue
    fi

    # Only evaluate past slots
    if (( SLOT <= CURRENT_SLOT )); then
      local OUTPUT BLOCK_PRODUCED=0 REWARD="0.000000000"
      OUTPUT="$($CMD block "$SLOT" 2>&1 || true)"

      if [[ $OUTPUT == *"Total Rewards:"* ]]; then
        ((PRODUCED++))
        REWARD=$(awk '/Total Rewards:/ {print $3}' <<< "$OUTPUT" | sed 's/‚óé//')
        BLOCK_PRODUCED=1
        TOTAL_REWARD=$(bc -l <<< "$TOTAL_REWARD + $REWARD")
        echo "‚úÖ Slot $SLOT produced ‚Ä¢ reward $REWARD SOL"
      elif [[ $OUTPUT == *"was skipped,"* ]]; then
        ((SKIPPED++))
        echo "‚ùå Slot $SLOT skipped"
      elif [ "$PRODUCED_IN_DB" = "0" ]; then
        ((UPDATED++))
        echo "üîÑ Slot $SLOT updated"
      fi

      # Write single-slot metrics to InfluxDB
      local TIMESTAMP LINE
      TIMESTAMP=$(date +%s%N)
      LINE="blockmetrics,host=${HOST},epoch=${CURRENT_EPOCH},slot=${SLOT},pubkey=${IDENTITY_KEY} produced=${BLOCK_PRODUCED},reward=${REWARD} ${TIMESTAMP}"
      curl -s -XPOST "$INFLUX_URL/api/v2/write?org=$INFLUX_ORG&bucket=$INFLUX_BUCKET&precision=ns" \
        -H "Authorization: Token $INFLUX_TOKEN" \
        --data-raw "$LINE" >/dev/null
    fi
  done

  # Store total reward per epoch if any
  if [[ $TOTAL_REWARD != 0 ]]; then
    local TS
    TS=$(date +%s%N)
    curl -s -XPOST "$INFLUX_URL/api/v2/write?org=$INFLUX_ORG&bucket=$INFLUX_BUCKET&precision=ns" \
      -H "Authorization: Token $INFLUX_TOKEN" \
      --data-raw "epoch_rewards,host=${HOST},epoch=${CURRENT_EPOCH} pubkey=\"${IDENTITY_KEY}\",total_reward_sol=${TOTAL_REWARD} ${TS}" >/dev/null
    echo "üí∞ Total reward for $HOST: $TOTAL_REWARD SOL"
  fi

  # Echo stats for caller
  printf "PRODUCED=%d\nSKIPPED=%d\nCACHED=%d\nUPDATED=%d\nTOTAL_REWARD=%s\n" \
         "$PRODUCED" "$SKIPPED" "$CACHED" "$UPDATED" "$TOTAL_REWARD"
}

###############################################################################
# MAIN EXECUTION FUNCTIONS
###############################################################################

# ===== FUNCTION TO COLLECT VALIDATOR METRICS FOR ALL NETWORKS =====
collect_all_validator_metrics() {
  echo "=========================================="
  echo "    COLLECTING VALIDATOR METRICS"
  echo "=========================================="

  $PROCESS_MAINNET  && send_validator_metrics "$MAINNET_VOTE_ACCOUNT"  "$MAINNET_IDENTITY"  "$MAINNET_RPC_API"  "$MAINNET_HOST"  "$MAINNET_STAKEWIZ_ENABLED" "$MAINNET_GOSSIP_ENABLED" "$MAINNET_JITO_MEV_ENABLED"
  $PROCESS_TESTNET  && send_validator_metrics "$TESTNET_VOTE_ACCOUNT"  "$TESTNET_IDENTITY"  "$TESTNET_RPC_API"  "$TESTNET_HOST"  "$TESTNET_STAKEWIZ_ENABLED" "$TESTNET_GOSSIP_ENABLED" "$TESTNET_JITO_MEV_ENABLED"
  $PROCESS_DEBUG    && send_validator_metrics "$DEBUG_VOTE_ACCOUNT"    "$DEBUG_IDENTITY"    "$DEBUG_RPC_API"    "$DEBUG_HOST"    "$DEBUG_STAKEWIZ_ENABLED" "$DEBUG_GOSSIP_ENABLED" "$DEBUG_JITO_MEV_ENABLED"
  $PROCESS_DEVNET   && send_validator_metrics "$DEVNET_VOTE_ACCOUNT"   "$DEVNET_IDENTITY"   "$DEVNET_RPC_API"   "$DEVNET_HOST"   "$DEVNET_STAKEWIZ_ENABLED" "$DEVNET_GOSSIP_ENABLED" "$DEVNET_JITO_MEV_ENABLED"
  $PROCESS_LOCALNET && send_validator_metrics "$LOCALNET_VOTE_ACCOUNT" "$LOCALNET_IDENTITY" "$LOCALNET_RPC_API" "$LOCALNET_HOST" "$LOCALNET_STAKEWIZ_ENABLED" "$LOCALNET_GOSSIP_ENABLED" "$LOCALNET_JITO_MEV_ENABLED"

  echo "‚úÖ Validator metrics collection completed"
  echo
}

# ===== FUNCTION TO COLLECT BLOCK METRICS FOR ALL NETWORKS =====
collect_all_block_metrics() {
  echo "=========================================="
  echo "      COLLECTING BLOCK METRICS"
  echo "=========================================="

  # Get the current epoch from Mainnet RPC (used for summary queries)
  CURRENT_EPOCH=$(curl -s "$MAINNET_RPC_API" -X POST -H "Content-Type: application/json" \
    -d '{"jsonrpc":"2.0","id":1,"method":"getEpochInfo"}' | jq -r '.result.epoch')
  echo "üìä Current epoch: $CURRENT_EPOCH"
  echo

  # Process clusters
  declare -A STATS

  if $PROCESS_MAINNET; then
    echo "üîÑ Processing Mainnet blocks"
    readarray -t arr <<< "$(check_produced_blocks "$MAINNET_IDENTITY" "$MAINNET_HOST" mainnet)"
    for kv in "${arr[@]}"; do STATS["MAINNET_${kv%%=*}"]="${kv#*=}"; done
    echo
  fi

  if $PROCESS_TESTNET; then
    echo "üîÑ Processing Testnet blocks"
    readarray -t arr <<< "$(check_produced_blocks "$TESTNET_IDENTITY" "$TESTNET_HOST" testnet)"
    for kv in "${arr[@]}"; do STATS["TESTNET_${kv%%=*}"]="${kv#*=}"; done
    echo
  fi

  if $PROCESS_DEBUG; then
    echo "üîÑ Processing Debug blocks"
    readarray -t arr <<< "$(check_produced_blocks "$DEBUG_IDENTITY" "$DEBUG_HOST" debug)"
    for kv in "${arr[@]}"; do STATS["DEBUG_${kv%%=*}"]="${kv#*=}"; done
    echo
  fi

  if $PROCESS_DEVNET; then
    echo "üîÑ Processing Devnet blocks"
    readarray -t arr <<< "$(check_produced_blocks "$DEVNET_IDENTITY" "$DEVNET_HOST" devnet)"
    for kv in "${arr[@]}"; do STATS["DEVNET_${kv%%=*}"]="${kv#*=}"; done
    echo
  fi

  if $PROCESS_LOCALNET; then
    echo "üîÑ Processing Localnet blocks"
    readarray -t arr <<< "$(check_produced_blocks "$LOCALNET_IDENTITY" "$LOCALNET_HOST" localnet)"
    for kv in "${arr[@]}"; do STATS["LOCALNET_${kv%%=*}"]="${kv#*=}"; done
    echo
  fi

  # Final summary
  format_number () { [[ -z $1 || $1 = "null" ]] && echo 0 || echo "$1"; }

  TOTAL_PRODUCED=$(( $(format_number "${STATS[MAINNET_PRODUCED]:-0}") +
                      $(format_number "${STATS[TESTNET_PRODUCED]:-0}") +
                      $(format_number "${STATS[DEBUG_PRODUCED]:-0}") +
                      $(format_number "${STATS[DEVNET_PRODUCED]:-0}") +
                      $(format_number "${STATS[LOCALNET_PRODUCED]:-0}") ))

  TOTAL_SKIPPED=$((  $(format_number "${STATS[MAINNET_SKIPPED]:-0}") +
                      $(format_number "${STATS[TESTNET_SKIPPED]:-0}") +
                      $(format_number "${STATS[DEBUG_SKIPPED]:-0}") +
                      $(format_number "${STATS[DEVNET_SKIPPED]:-0}") +
                      $(format_number "${STATS[LOCALNET_SKIPPED]:-0}") ))

  TOTAL_CACHED=$((   $(format_number "${STATS[MAINNET_CACHED]:-0}") +
                      $(format_number "${STATS[TESTNET_CACHED]:-0}") +
                      $(format_number "${STATS[DEBUG_CACHED]:-0}") +
                      $(format_number "${STATS[DEVNET_CACHED]:-0}") +
                      $(format_number "${STATS[LOCALNET_CACHED]:-0}") ))

  echo "=================================================="
  echo "            BLOCK METRICS SUMMARY                 "
  echo "=================================================="
  echo "‚úÖ Produced blocks:      $TOTAL_PRODUCED"
  echo "‚ùå Skipped blocks:       $TOTAL_SKIPPED"
  echo "üóÉÔ∏è  Cached blocks:        $TOTAL_CACHED"
  echo "üî¢ Slots processed:      $((TOTAL_PRODUCED + TOTAL_SKIPPED + TOTAL_CACHED))"
  echo "‚úÖ Block metrics collection completed"
  echo
}

###############################################################################
# MAIN EXECUTION
###############################################################################

main() {
  echo "=================================================="
  echo "    SOLANA VALIDATOR METRICS COLLECTOR"
  echo "=================================================="
  echo "üöÄ Starting metrics collection at $(date)"
  echo

  # Sequential execution to ensure reliability
  collect_all_validator_metrics
  collect_all_block_metrics

  echo "=================================================="
  echo "üéâ All metrics collection completed successfully!"
  echo "üìÖ Finished at $(date)"
  echo "=================================================="
}

# Execute main function
main "$@"
